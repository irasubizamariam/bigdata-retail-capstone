{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(\"/bin/r/Online Retail (2).xlsx\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "v12AoBOSC2JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Clean the data\n",
        "df = df.dropna(subset=['CustomerID'])         # Remove missing customer IDs\n",
        "df = df[df['Quantity'] > 0]                   # Remove negative quantities\n",
        "df = df[df['UnitPrice'] > 0]                  # Remove zero or negative prices\n",
        "\n",
        "# Add new features\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "df['Hour'] = df['InvoiceDate'].dt.hour\n",
        "df['Day'] = df['InvoiceDate'].dt.day_name()\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# ðŸ“Š Plot 1: Orders by Day\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Day', data=df, order=[\n",
        "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
        "plt.title(\"ðŸ—“ï¸ Orders by Day of the Week\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ðŸ“Š Plot 2: Orders by Hour\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['Hour'], bins=24, kde=False)\n",
        "plt.title(\"ðŸ•’ Orders by Hour of the Day\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Number of Orders\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x14WXMnBEFXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Create a binary target: High orders hour or not\n",
        "# Let's define \"high order hour\" as hours with orders above median\n",
        "\n",
        "hour_counts = df['Hour'].value_counts()\n",
        "median_orders = hour_counts.median()\n",
        "\n",
        "# Map each hour to whether it has high order count or not\n",
        "high_order_hours = hour_counts > median_orders\n",
        "high_order_hours = high_order_hours.astype(int)\n",
        "\n",
        "# Prepare dataset for classification\n",
        "X = df[['Hour']]               # Feature: hour of order\n",
        "y = df['Hour'].map(high_order_hours)  # Target: high order hour (1) or not (0)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "tIeL6K9bFIJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Sample data similar to Online Retail dataset\n",
        "data = {\n",
        "    'InvoiceNo': ['536365', '536366', '536367', '536368', '536369'],\n",
        "    'StockCode': ['85123A', '71053', '84406B', '84029G', '84029E'],\n",
        "    'Description': [\n",
        "        'WHITE HANGING HEART T-LIGHT HOLDER',\n",
        "        'WHITE METAL LANTERN',\n",
        "        'CREAM CUPID HEARTS COAT HANGER',\n",
        "        'KNITTED UNION FLAG HOT WATER BOTTLE',\n",
        "        'RED WOOLLY HOTTIE WHITE HEART.'\n",
        "    ],\n",
        "    'Quantity': [6, 6, 8, 6, 6],\n",
        "    'InvoiceDate': [\n",
        "        datetime(2010, 12, 1, 8, 26),\n",
        "        datetime(2010, 12, 1, 8, 28),\n",
        "        datetime(2010, 12, 1, 8, 34),\n",
        "        datetime(2010, 12, 1, 8, 35),\n",
        "        datetime(2010, 12, 1, 8, 45)\n",
        "    ],\n",
        "    'UnitPrice': [2.55, 3.39, 2.75, 3.39, 3.39],\n",
        "    'CustomerID': [17850, 17850, 13047, 13047, 13047],\n",
        "    'Country': ['United Kingdom'] * 5\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add derived columns\n",
        "df['Hour'] = df['InvoiceDate'].dt.hour\n",
        "df['Day'] = df['InvoiceDate'].dt.day_name()\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Save cleaned dataset to CSV\n",
        "df.to_csv('cleaned_online_retail.csv', index=False)\n",
        "\n",
        "print(\"File 'cleaned_online_retail.csv' has been created in your Colab environment.\")\n"
      ],
      "metadata": {
        "id": "wmLLd8ten-J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# Sample data similar to Online Retail\n",
        "data = {\n",
        "    'InvoiceNo': ['536365', '536366', '536367', '536368', '536369'],\n",
        "    'StockCode': ['85123A', '71053', '84406B', '84029G', '84029E'],\n",
        "    'Description': [\n",
        "        'WHITE HANGING HEART T-LIGHT HOLDER',\n",
        "        'WHITE METAL LANTERN',\n",
        "        'CREAM CUPID HEARTS COAT HANGER',\n",
        "        'KNITTED UNION FLAG HOT WATER BOTTLE',\n",
        "        'RED WOOLLY HOTTIE WHITE HEART.'\n",
        "    ],\n",
        "    'Quantity': [6, 6, 8, 6, 6],\n",
        "    'InvoiceDate': [\n",
        "        datetime(2010, 12, 1, 8, 26),\n",
        "        datetime(2010, 12, 1, 8, 28),\n",
        "        datetime(2010, 12, 1, 8, 34),\n",
        "        datetime(2010, 12, 1, 8, 35),\n",
        "        datetime(2010, 12, 1, 8, 45)\n",
        "    ],\n",
        "    'UnitPrice': [2.55, 3.39, 2.75, 3.39, 3.39],\n",
        "    'CustomerID': [17850, 17850, 13047, 13047, 13047],\n",
        "    'Country': ['United Kingdom'] * 5\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add derived columns\n",
        "df['Hour'] = df['InvoiceDate'].dt.hour\n",
        "df['Day'] = df['InvoiceDate'].dt.day_name()\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Save to CSV\n",
        "filename = 'cleaned_online_retail.csv'\n",
        "df.to_csv(filename, index=False)\n",
        "\n",
        "# Download file link\n",
        "files.download(filename)\n"
      ],
      "metadata": {
        "id": "2T3DHN_Qp7S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3347e1"
      },
      "source": [
        "# Task\n",
        "Prepare the data from \"/content/cleaned_online_retail.csv\" for import into Power BI Desktop by performing necessary data cleaning and transformations to avoid errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3714d118"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "### Subtask:\n",
        "Load the data from the `cleaned_online_retail.csv` file into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e41b3d78"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the cleaned data from the CSV file into a pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6958bbc"
      },
      "source": [
        "df_cleaned = pd.read_csv('cleaned_online_retail.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f82284f"
      },
      "source": [
        "## Check data types\n",
        "\n",
        "### Subtask:\n",
        "Examine the data types of each column and convert them to appropriate types if necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34347efc"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the data types of each column to identify columns that might need type conversion for Power BI.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61d5ef76"
      },
      "source": [
        "df_cleaned.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69483ff3"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the 'InvoiceDate' column to datetime objects as it is currently of type object and should be a datetime type for proper handling in Power BI. The other columns seem to have appropriate data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d938b37"
      },
      "source": [
        "df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])\n",
        "df_cleaned.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20c38b8b"
      },
      "source": [
        "## Handle missing values\n",
        "\n",
        "### Subtask:\n",
        "Identify and handle any missing values in the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d98804a5"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for missing values in each column of the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39e1a0bd"
      },
      "source": [
        "print(\"Missing values before handling:\")\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2bf14b3"
      },
      "source": [
        "## Check for duplicates\n",
        "\n",
        "### Subtask:\n",
        "Identify and remove any duplicate rows if necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49aa582f"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for duplicate rows in the DataFrame and remove them if found, then print the row counts before and after removal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15c26786"
      },
      "source": [
        "print(\"Number of rows before removing duplicates:\", len(df_cleaned))\n",
        "df_cleaned.drop_duplicates(inplace=True)\n",
        "print(\"Number of rows after removing duplicates:\", len(df_cleaned))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c2792fe"
      },
      "source": [
        "## Data consistency checks\n",
        "\n",
        "### Subtask:\n",
        "Perform any necessary checks to ensure data consistency (e.g., check for negative quantities or prices if not already handled).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08328147"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for and remove rows with non-positive Quantity or UnitPrice and report the number of rows before and after the operation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "821d8a50"
      },
      "source": [
        "print(\"Number of rows before checking Quantity and UnitPrice:\", len(df_cleaned))\n",
        "\n",
        "# Filter out rows with non-positive Quantity or UnitPrice\n",
        "df_cleaned = df_cleaned[(df_cleaned['Quantity'] > 0) & (df_cleaned['UnitPrice'] > 0)]\n",
        "\n",
        "print(\"Number of rows after checking Quantity and UnitPrice:\", len(df_cleaned))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "153062fa"
      },
      "source": [
        "## Save cleaned data\n",
        "\n",
        "### Subtask:\n",
        "Save the cleaned and prepared data to a new CSV file that is ready for import into Power BI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbca3056"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the cleaned DataFrame to a CSV file for Power BI.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d46a3efc"
      },
      "source": [
        "filename = 'cleaned_online_retail_for_powerbi.csv'\n",
        "df_cleaned.to_csv(filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05c8eb77"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial data loaded from `cleaned_online_retail.csv` contained an `InvoiceDate` column with an 'object' data type, which was successfully converted to `datetime64[ns]`.\n",
        "*   There were no missing values found in the dataset.\n",
        "*   No duplicate rows were identified or removed from the dataset.\n",
        "*   All entries in the `Quantity` and `UnitPrice` columns already contained positive values, and no rows were removed during the consistency check for these columns.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The data is now in a clean and appropriate format (`cleaned_online_retail_for_powerbi.csv`) for direct import and analysis in Power BI Desktop.\n",
        "*   Further analysis in Power BI can now focus on creating visualizations and reports without needing significant data cleaning steps within Power BI itself.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e42cb1d"
      },
      "source": [
        "## Save cleaned data\n",
        "\n",
        "### Subtask:\n",
        "Save the cleaned and prepared data to a new CSV file that is ready for import into Power BI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "628504fc"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the cleaned DataFrame to a CSV file for Power BI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97c7441"
      },
      "source": [
        "filename = 'cleaned_online_retail_for_powerbi.csv'\n",
        "df_cleaned.to_csv(filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}